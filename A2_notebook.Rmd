---
title: "Structure Learning"
output:
  pdf_document: default
  html_notebook: default
---

## Structure Learning a Bayesian Network given bike sharing data

Let's start with importing the necessary libraries.

```{r}
#if (!requireNamespace("BiocManager", quietly = TRUE))
#  install.packages("BiocManager")
#BiocManager::install("RBGL")
#install.packages("birankr")
#install.packages("bnlearn")
#intall.packages("SID")
library(birankr)
library(bnlearn)
library(dagitty)
library(ggplot2)
library(ggpubr)
library(SID)
```

Let's now load the data from storage and determine the indices at which each day starts.

```{r}
# use hourly data as source
hourly.data <- read.csv("hour.csv", header=TRUE)
# determine indices of day starts
day.starts <- hourly.data$instant[!duplicated(hourly.data$dteday)]

write(sprintf("Number of days in the dataset: %d", length(day.starts)), stdout())
```
Now let's make the hourly dataset a daily dataset by aggregating over the hour variable.

```{r include=FALSE}
daylength <- function(days)
{
  result <- NULL
  L <- 38.8951  # latitude Washington D.C.
  for (day in days) 
  {
    P = asin(0.39795 * cos(0.2163108 + 2 * atan(0.9671396 * tan(.00860 * (day - 186)))))
    
    D <- 24 - (24 / pi) * 
      acos(
        (sin(0.8333 * pi / 180) + sin(L * pi / 180) * sin(P))
        / 
          (cos(L * pi / 180) * cos(P))
      )
    
    result <- c(result, D)
  }
  return(result)
}


gasprice.per.week <- c(
  3.114, 3.129, 3.141, 3.164, 3.172, 3.165, 3.175, 3.181, 3.209, 3.37, 3.519,
  3.567, 3.562, 3.576, 3.657, 3.757, 3.828, 3.898, 3.981, 4, 3.993, 3.912,
  3.847, 3.805, 3.766, 3.727, 3.672, 3.634, 3.687, 3.738, 3.759, 3.772, 3.738,
  3.67, 3.625, 3.626, 3.666, 3.667, 3.634, 3.567, 3.504, 3.462, 3.498, 3.494,
  3.476, 3.454, 3.454, 3.416, 3.373, 3.338, 3.334, 3.309, 3.313, 3.346, 3.44,
  3.46, 3.494, 3.548, 3.571, 3.627, 3.67, 3.748, 3.78, 3.793, 3.828, 3.882,
  3.924, 3.974, 3.955, 3.93, 3.874, 3.809, 3.764, 3.715, 3.657, 3.603, 3.534,
  3.477, 3.417, 3.384, 3.434, 3.482, 3.564, 3.569, 3.637, 3.725, 3.75, 3.781,
  3.823, 3.86, 3.953, 3.907, 3.893, 3.911, 3.877, 3.787, 3.692, 3.677, 3.66,
  3.657, 3.637, 3.594, 3.545, 3.486, 3.471, 3.5
)
gasprice <- function(days)
{
  week.starts <- c(days[hourly.data[day.starts, "weekday"] == 1], length(days) + 1)
  result <- NULL
  current.monday <- 1
  for (week in 1:length(week.starts))
  {
    next.monday <- week.starts[week]
    result <- c(result, rep(gasprice.per.week[week], next.monday - current.monday))
    current.monday <- next.monday
  }
  return(result)
}

load.data <- function()
{
  data <- data.frame(
    day=seq_along(day.starts),
    season=hourly.data[day.starts, "season"] %% 4 > 1,
    holiday=hourly.data[day.starts, "holiday"] == 1,
    workingday=hourly.data[day.starts, "weekday"] %% 6 != 0,
    weathersit=ordered(1, levels=1:3),
    daylength=daylength(seq_along(day.starts)),
    rallyprotest=seq_along(day.starts) %in% c(
      274, 288, 289, 313, 314, 315, 316, 317, 318, 319, 320, 321,
      322, 323, 324, 325, 326, 327, 376, 416, 449, 575, 673, 687
    ),
    gasprice=gasprice(seq_along(day.starts)),
    hum=-1,
    windspeed=-1,
    temp=-1,
    atemp=-1,
    casual=-1,
    registered=-1
  )
  
  # aggregate over hours to get daily variables
  day.intervals <- c(day.starts, nrow(hourly.data) + 1)
  for (day in data$day)
  {
    day.data <- hourly.data[day.intervals[day]:(day.intervals[day + 1] - 1),]
    
    if (sum(day.data$weathersit == 3 | day.data$weathersit == 4) >= 3)
    {
      data$weathersit[day] <- 3
    } else if (sum(day.data$weathersit == 2 | day.data$weathersit == 3 | day.data$weathersit == 4) >= 3)
    {
      data$weathersit[day] <- 2
    } else
    {
      data$weathersit[day] <- 1
    }
    
    data[day, "hum"] <- mean(day.data$hum)
    data[day, "windspeed"] <- mean(day.data$windspeed)
    data[day, "temp"] <- mean(day.data$temp)
    data[day, "atemp"] <- mean(day.data$atemp)
    
    data[day, "casual"] <- sum(day.data$casual)
    data[day, "registered"] <- sum(day.data$registered)
  }
  return(data)
}
```

```{r}
data <- load.data()
write("Columns in the daily dataset:", stdout())
write(colnames(data), stdout())
```
Now that we have the data, let's make sure that the types are correct.

```{r}
# scale all variables except the ordinal weather situation to z-scores
numeric.data <- data.frame(lapply(subset(data, select=-weathersit), as.numeric))
scaled.data <- data.frame(scale(numeric.data))

# put ordinal weather situation back in dataframes
data <- cbind(numeric.data, weathersit=data$weathersit)
scaled.data <- cbind(scaled.data, weathersit=data$weathersit)
scaled.data$atemp[595] <- -scaled.data$atemp[595]  # reverse outlier
```

```{r include=FALSE}
save.network <- function(g)
{
  # predict with SEM using bnlearn package
  fit <- bn.fit(g, data)  # use non-scaled version of data for prediction
  years <- subset(data, select=-c(casual, registered))
  years$casual <- predict(fit, node="casual", data=years, method="bayes-lw")
  years$registered <- predict(fit, node="registered", data=years, method="bayes-lw")
  years.list <<- append(years.list, list(years))
  graphs <<- append(graphs, list(g))
}

plot.preds <- function(i, title)
{
  ggarrange(
    ggplot(data) +
      geom_line(aes(x=day, y=casual)) +
      geom_line(aes(x=day, y=casual + registered)) +
      geom_ribbon(aes(x=day, ymin=0, ymax=casual), fill="red", alpha=0.5) +
      geom_ribbon(aes(x=day, ymin=casual, ymax=casual + registered), fill="blue", alpha=0.5) +
      ylim(-600, max(data$casual + data$registered)) +
      xlab("days") + ylab("True total number of users"),
    ggplot(years.list[[i]]) +
      geom_line(aes(x=day, y=casual)) +
      geom_line(aes(x=day, y=casual + registered)) +
      geom_ribbon(aes(x=day, ymin=0, ymax=casual), fill="red", alpha=0.5) +
      geom_ribbon(aes(x=day, ymin=casual, ymax=casual + registered), fill="blue", alpha=0.5) +
      ylim(-600, max(data$casual + data$registered)) +
      ggtitle(title) + xlab("days") + ylab("Predicted total number of users"),
    nrow=2
  )
}

arcs_mses <- function(titles)
{
  ntitles <- length(titles)
  metrics <- data.frame(matrix(
    ncol=ntitles,
    nrow=4,
    dimnames=list(c("nr.arcs", "mse.casual", "mse.registered", "mse.total"), titles)
  ))
  
  for (i in 1:ntitles)
  {
    nr.arcs <- length(arcs(graphs[[i]])) / 2
    mse.casual <- mean((data$casual - years.list[[i]]$casual)^2)
    mse.registered <- mean((data$registered - years.list[[i]]$registered)^2)
    mse.total <- mean((
      (data$casual + data$registered) - 
      (years.list[[i]]$casual + years.list[[i]]$registered)
    )^2)
    metrics[,i] <- c(nr.arcs, mse.casual, mse.registered, mse.total)
  }
  
  return(metrics)
}

graphsDists <- function(titles)
{
  ntitles <- length(titles)
  dists <- list(
    data.frame(matrix(
      ncol=ntitles,
      nrow=ntitles,
      dimnames=list(titles, titles)
    )),
    data.frame(matrix(
      ncol=ntitles,
      nrow=ntitles,
      dimnames=list(titles, titles)
    ))
  )
  
  for (i in 1:ntitles)
  {
    for (j in 1:ntitles)
    {
      dists[[1]][i,j] <- structIntervDist(amat(graphs[[i]]), amat(graphs[[j]]))$sid
      dists[[2]][i,j] <- hammingDist(amat(graphs[[i]]), amat(graphs[[j]]))
    }
  }
  
  return(dists)
}

graphsPageRanks <- function(titles)
{
  ntitles <- length(titles)
  pageRanks <- data.frame(matrix(
    ncol=ntitles,
    nrow=length(data),
    dimnames=list(colnames(data), titles)
  ))
  
  for (i in 1:ntitles)
  {
    graphPageRanks <- pagerank(data.frame(arcs(graphs[[i]])), is_bipartite=FALSE)
    graphPageRanks <- graphPageRanks[order(match(graphPageRanks$from, colnames(data))),]
    pageRanks[,i] <- graphPageRanks$rank
  }
  
  return(pageRanks)
}

years.list <- list()
graphs <- list()
```

### Hill Climbing
We are finally ready to start trying out structure learning algorithms.
First, we will try the hill climbing algorthm which learns structure based on a score.

```{r}
g <- hc(scaled.data, score="aic-cg") #, k=1)
save.network(g)
plot(g)
```

```{r}
g <- hc(scaled.data, score="bic-cg")
save.network(g)
plot(g)
```

```{r}
g <- hc(scaled.data, score="loglik-cg")
save.network(g)
plot(g)
```
```{r}
scaled.data100 <- sample(scaled.data)
prop <- 0.8
scaled.data80 <- scaled.data100[1:585,]
scaled.data20 <- scaled.data100[586:731,]
g <- hc(scaled.data80, score="pred-loglik-cg", newdata=scaled.data20)
save.network(g)
plot(g)
```

### PC
Next, we will consider a variant of the PC algorithm.

```{r}
# g <- pc.stable(scaled.data, test="mi-cg", alpha=0.005)

# write("\nArcs in the DAG:", stdout())
# write(length(arcs(g)) / 2, stdout())

# plot(g)
```

### Manual
Finally, we can compare the structure learning algorithms to our manual effort.

```{r}
# full Bayesian network is specified below using dagitty package
manual.g <- dagitty(paste('dag {',
    ####################################
    #            Variables             #
    ####################################
    # weather variables
    'weathersit [pos="-0.402,-0.329"]
    hum [pos="-0.412,-0.329"]
    windspeed [pos="-0.412,-0.337"]
    temp [pos="-0.421,-0.324"]
    atemp [pos="-0.421,-0.331"]',
    
    # day variables
    'season [pos="-0.428,-0.312"]
    day [pos="-0.422,-0.297"]
    workingday [pos="-0.402,-0.319"]
    holiday [pos="-0.403,-0.301"]',
    
    # extra variables
    'daylength [pos="-0.422,-0.316"]
    gasprice [pos="-0.422,-0.308"]
    rallyprotest [pos="-0.402,-0.308"]',
    
    # outcome variables
    'casual [pos="-0.412,-0.304"]
    registered [pos="-0.412,-0.321"]',
    
    ####################################
    #            Connections           #
    ####################################
    # weather relations
    'season -> daylength -> temp -> atemp
    weathersit -> {windspeed -> hum} -> atemp',
    
    # gas price relations
    '{season day} -> gasprice',
    
    # outcome relations
    '{day atemp workingday weathersit gasprice daylength holiday rallyprotest} -> casual
    {day atemp workingday weathersit gasprice daylength} -> registered',
'}'))
manual.g <- model2network(toString(manual.g, "bnlearn"))
save.network(manual.g)
plot(manual.g)
```

### Inspect the predictions of the total number of users
```{r}
plot.preds(1, "aic-cg")
plot.preds(2, "bic-cg")
plot.preds(3, "loglik-cg")
plot.preds(4, "pred-loglik-cg")
plot.preds(5, "manual")
```
### Inspect the evaluation metrics
```{r}
titles <- c("aic-cg","bic-cg","loglik-cg","pred-loglik-cg","manual")
arcs.mses <- arcs_mses(titles)
print(arcs.mses)
```
```{r}
pageRanks <- graphsPageRanks(titles)
print(pageRanks)
```
```{r}
dists <- graphsDists(titles)
write("Structural Intervention Distance followed by Structural Hamming Distance:", stdout())
print(dists[[1]])
print(dists[[2]])
```
